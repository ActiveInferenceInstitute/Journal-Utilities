UNKNOWN:
Thank you.

Thank you.

Thank you.

Thank you.

Bye.

Thank you.

Thank you.

so

Thank you for watching.

Bye.

Thank you.

Thank you.

Thank you.


SPEAKER_00:
Hello everyone.

Welcome to Complexity Weekend.

This is the August 2020 Heartbeat event.

We three are your organizers for this event and we are just going to introduce ourselves and by way of saying hi and welcoming you to the community, go over some of the goals for this event.

So Steve, why don't you introduce yourself and bring up the first goal?


SPEAKER_01:
Oh, what is the first goal?


SPEAKER_00:
Whatever you wanted to think was a good goal to talk about.

Whatever you want it to be.


SPEAKER_01:
Yeah, I'm Steve Gans.

Yeah, we put together this heartbeat session as a way of creating some rhythm between the main Complexity Weekend events.

And so, yeah, one of the goals is to keep people in touch about the projects they've been working on.

New people who are jumping in now, give them a chance to see what's been going on over time with the various projects, and we'll pass it on.


SPEAKER_00:
Sean?


SPEAKER_03:
Yeah, I think a goal that I think of for these monthly gatherings for our community of practice is really not only to reconnect with the teams and kind of keep that momentum going, but really also just get that little nugget of complexity science insight.

That's what we're all here for.

That's why we're all here under the banner of complexity is that we like thinking about these systems, these types of systems of behavior.

So really just getting that little nugget of a little bit of new knowledge each time you engage with this community.

That's what I'm looking forward to.


SPEAKER_00:
Cool, I'm Daniel and I think the thing that is a goal and an excitement is always just the optimization of our platforms for feedback and for making sure that the experience that we're sharing is just unhindered by these other things that might get in the way of all these awesome goals that the two of you mentioned and other goals that you could freely post about in the chat.

So let's go to the slides, Sean, if you wanted to go first.


SPEAKER_03:
Sure, yeah, I'll do that.

Let me share my screen right now.

Right here.

Nice.

Yeah, welcome, everyone.

So glad to have you here.

And yeah, this is just the first of kind of, or not the first, but the series of monthly events that we like to do between these kind of six-month kind of bigger Complexity Weekend events where we form new teams, kind of have a really peak to our energy kind of cycle all year.

These monthly events are really just to keep the momentum going

and learn a little bit along the way.

This is August's monthly heartbeat.

Our mission for this whole thing, so everyone is familiar or remembers, it's really empowering new and existing teams to tackle the world's toughest problems by applying complexity science, by applying diverse perspectives and problem-solving strategies, and really to handle some of these problems that just cannot be solved in siloed fields or any of that type of thinking.

I want to thank Michael Garfield,

for the amazing music that we always start the top of our live stream with.

It is complexity-inspired music.

And if you want to know what I mean by that, ping me after, at Dr. Proton in KeyBase, and I'll let you know what that means.

So one way to start that would be kind of fun is just to wake up this complexweekend.public KeyBase team that we're basing all these heartbeats out of, is really just to think about this impossible-to-answer question, right?

What is complexity science to you?

And so if you can think about this and mull it over for a minute, we'd really love for people to start sharing this in the Keybase itself.

So if you're not in Keybase yet, we'll talk about it in a minute because you're going to, you know, Keybase is really the back end for this whole community.

And being in our Keybase teams is the key thing you need to do to really participate.

We'll talk about that in a minute.

But if you're in right now, make a post and hashtag general, hashtag heartbeat about what complexity science really means to you.

We got some inspirational examples right now to think about.

And while you're making that post and thinking about it, I just want to recap a little bit, you know, what is our community of practice and really the best picture we have right now is the snapshot we gathered in May when we did our last big gathering of, you know, 150 people came together.

We formed, I think, seven teams that we'll talk about.

and learned a lot of complexity by doing, by actually trying to apply it to really difficult problems.

And it was actually right when COVID was kicking off early on in that cycle.

So it was really interesting.

We actually did a COVID themed event last time, which was just a very interesting lens on all this complexity thinking.

But we had 151 participants, a lot of complexity beginners.

I really want to stress this.

If you have never even really heard of complexity science, you're just curious, that's totally okay.

We're all here to help each other learn and really learn by doing.

And if you look at the breakdown a little bit, there's a lot of academics.

There is no real plurality.

We are somewhat diverse.

I'd like to see this get a little more diverse over time.

But given that we are very strongly academic oriented right now in this snapshot, I want to stress that how can we translate complexity science knowledge into actual immediate impact in the real world?

And that's something I really want to stress.

And you can also see our locations are all over the globe, a lot of us, but all over the globe.

And this is just the community right now, it's going to keep growing.

These were the seven teams that came out of May, four of which have representatives here at the heartbeat now in this month's heartbeat.

And again, this is just the snapshot from May, there's going to be more teams as we keep doing these events and keep keep these heartbeats going to kind of keep the

community active and engaged in this community of practice really practicing.

And so with that, I want to go ahead and pass it over to Steven to kind of talk about what the proceedings for today looks like, what the design was kind of going into it.


SPEAKER_01:
Okay.

Yeah.

Thanks, Sean.

So with the program today, we have really been looking to balance a couple of interests here.

First,

continuing some of the spirit of the larger complexity weekend events and so we have more great complexity content and more group work.

We want to breathe some energy into some of these team

projects that have been continuing since the weekend event.

So give everybody a chance to reconnect with their teams, maybe get some new people who are expressing an interest in these projects and

Finally, also encourage some interaction between the teams.

Really create a community of practice around applying complexity concepts to real-world problems.

And so what we are looking to do here is we're currently in this first introduction.

Welcome.

But we've got some great presentations coming up.

We'll be hearing from Michael Zargum on CAD-CAD, which I understand is computer-aided design applied to complex adaptive systems, although I guess that would be more of CAD-CAS.

We'll let him explain that.

We will be going next to Jason Larkin, who will be helping us make sense of what we're all doing here.

So a number of technologies we will be switching between.

You're seeing the live stream now.

We'll be heading next into the Gather sessions, which will be a way to sort of randomly

meet each other online and video chat.

We'll be doing that immediately after the live stream presentation.

So the idea being that we can use some of the material that we're all hearing together here as just grist for conversation in this, I guess, online town has been renamed Gather.

We'll then go into separate Jitsi rooms, if you can point me back to the schedule there.

Sean?

Yeah, thank you.

So, yeah, this next section there will be all of us in a shared Jitsi where we'll give each of the teams a chance to speak a little bit about what their project is, what they've been working on.

and then engage everybody else in the Jitsi around a conversation on that.

Let's share a little bit of information and ideas for each project.

And then we'll go into separate breakout sessions for the next portion where each team will have an area where

in their own room where they can meet with whoever wants to come visit.

This is the idea of a percolation of ideas through the community.

Anyone can drop by and see what a team is doing.

And then finally,

I'm sorry, show me the schedule one more time there.

Yeah, this last section will be separate breakout sessions for each team, and we'll let the facilitator circle through and talk to each team about what they've been working on and give them a few pearls of wisdom.


SPEAKER_00:
Awesome.

Thank you.


SPEAKER_01:
Okay, I think that's about it.

So, yeah, so there's various technologies, as we said here, the gather sessions, I talked about a little bit already, the Jitsi rooms.

If you haven't seen those, it's, yeah, basically just another tool for video meetings, but we find it works well for us.

And Keybase is one thing you may not have seen much of yet.

But we used it pretty heavily at the Complexity Weekend event.

And it is currently owned by Zoom, I believe.

But I'm not sure how much of an intro I can do here.

But there are chats where on the left bar you can see various

chat streams.

And at the bottom, if you go to the chat and go down to the bottom, you'll see various channels, including general channel and heartbeat channel.

And we can converse on there.

And you'll need to update your Keybase name, I believe, and use your Keybase name wherever you are interacting on the system so that people can find you on Keybase.

Perfect.


SPEAKER_00:
great let's uh dan do you want to go ahead and cover um yeah in a minute or two the um yep so what are the rules and principles for this complex system that will help us across the platforms or in the presence of technological glitches or anything we've written several of them down here just to the extent that's possible uh

improve your audio-visual experience for yourself and for other people just through clear language.

And always feel free to reach out about anything else to us if you want help with something on the technical side.

We really encourage co-ownership of this whole community of practice.

And also, I'd just like to take a moment to recognize Steve for stepping up from being a participant to helping us organize this event.

And the schedule is definitely something

was really reached with your wise input.

And as far as structuring teams, and we hope that participants can feel that, that this is something that was co-organized from the beginning.

And we really just want this to be whatever you make it to be.

So treat each other nicely.

Okay.

Yep.

And also a few more community guidelines that we've just found help contribute to healthy and productive and educational events.

Participate fully to the extent that you'd like and have a travel mindset, have a yes and mindset.

Be curious.

that's what complexity science is all about is being curious in this community context and uh to the extent that it's possible just keep things private what you hear here is here to stay in the jitsis unless the person gives you permission to share and we encourage various other principles that we hope to go over with you more at future events or on the text back end and last slide

big announcement slash save the date.

We're really happy to announce that on October 16th to 18th, 2020, so in about two months from now, we'll be having another full weekend, Complexity Weekend facilitated hackathon.

And we have a lot of cool planning already in the works here.

A lot of the facilitators and the participants from May or from 2019 will be here again, as well as a lot of new people already.

Please get in touch with us if you just want to stay updated on where this project is going.

If you want to get in touch with us about potentially being a facilitator or you'd like to recommend somebody who'd like to be a facilitator potentially, or if you just want to enter your email address on complexityweekend.com.

Tom, where we will announce when registration opens at the beginning of September.

Um, it's really exciting.

So we're happy to have this last bringing together of community for a synchronous event before we have this really big event in October.

And that's all for the introductory section are

first speaker, Michael Zargum is here.

Michael was a facilitator for us in 2019 in San Francisco and in May as well remotely.

And so it's always a pleasure to hear you talk, Michael, and please take it away.

We'll just disable our video and looks great with a picture in picture.

Thanks and go for it.


SPEAKER_04:
Awesome.

Thank you very much.

So I'm Michael Zargum, and I generally go by Zargum, so feel free to refer to me as that.

This is Conrad, my daughter, who I am in charge of at the moment.

She says hi.

Hopefully she will remain calm for the duration of this talk.

So we're going to talk a bit about...

applied complex systems engineering for social impact a big part of this discussion is going to revolve around complexity and how we apply it for designing algorithms for community decision-making and this particular research is a collaboration between Myself my firm block science and the common stack, which is an open source project working on applications to community management

So the first thing I want to point out is that we really need to be able to scale social responsibility in order to make more effective decisions as communities.

Right now, we're kind of stuck with a lot of challenges.

Top-down governance systems are breaking down due to sort of

you know binary choices time box windows um just a lot of things that are sort of structurally problematic and rather than just saying the choices are bad we can sort of start to ask what the sort of phenomena or intrinsic properties of these systems are and maybe how we could work towards uh reorganizing ourselves to make better decisions and a pretty important concept here is

polycentric governance.

It's something that is best read about in like Ostrom's work.

For the purpose of this talk, I'll probably just kind of move into the technical stuff on complex systems, but from a motivational perspective, we very much want to find ways to use new tools to solve what we would consider old problems and not solve them ultimately forever, just sort of do a better job managing collective decision making.

So in this context, I'm frequently asked to explain complex systems for people who don't have a complexity background.

And I'm going to use it here anyway as a bridge.

So we work with systems, they're just abstractions, they're representations of holes and their relationships with parts.

And in particular, complex systems have

non-trivial and non-obvious relationships between the parts and each other and the whole in the sense that you can't sort of predict the system level behavior just from examining the part level behavior and sort of, in a sense, linearly adding it up.

And in particular, social systems are a subset of complex systems, and we tend to look at economic and political economic systems.

In particular, we're going to talk about applications from a field called DAOs, or Decentralized Autonomous Organizations, which are essentially just internet-based sort of collectives which use cryptographic technology as the backend to their decision-making procedures.

In my work, in our practice, we're very careful to apply engineering principles, and in particular, we call out the institutional aspects of engineering

much the, you know, hey, we build stuff, but understanding a sort of holism, multi-specialization, understanding interfaces between parts, you know, managing complexity without trying to get rid of it.

So, you know, understanding that the complexity can be placed under the hood and sort of taken care of, sort of understood, sensitivity tested,

et cetera, and then make a simple experience for the public without sort of simplifying the whole consideration to a sort of unsafe reduction.

And in particular, we look at the full life cycle of the system we're trying to build.

And a very important aspect of the engineering discipline is that

It's public good oriented.

Actually, in a sense, the engineering field manages the relationship between society and technology.

And again, this is the sort of institution of the profession.

And in practice, there's a set of processes and procedures that help

us do this and tend to talk in terms of design and development and the way in which we do validation and verification.

I definitely recommend anyone who's interested actually read a little bit about validation and verification, the differences between them and how they go together to create whole systems.

Since we're working on social systems, it's really important to talk about how computational social science works and the relationship between the known and the unknown in our system models and how that relates to emergence.

When dealing with individuals, we generally want to think in terms of open systems.

meaning there's information outside of the system that's communicated into that system or expressed by the agent's choices, the actions they take or don't take.

But that's private information that they hold that's maybe related to their private signals, but also might be their private preferences.

And ultimately, there's a sort of

distributed state information spread out across the agents and that when they interact through a process they're going to have effects on each other they're going to have effects on the system state and even if the laws of motion or the aspects of the process model are deterministic because of this open system we're going to have a sort of non deterministic outcome we're going to basically have

a deterministic process as the consequence of your actions, but the actions themselves are non-deterministic, which is part of the reason why we get interesting emergence phenomena, because there's a feedback loop through the agents themselves and their choices of what to express.

In a lot of ways, we can actually think of this as a signal processing problem.

where the process model or the mechanisms that one designs are actually filtering or coloring the information that's being expressed by the agents participating in the system.

So from a economics perspective, we tend to discuss this in terms of institutional economics, where we kind of zoom in on this sort of meso layer.

We have a macro perspective, which is associated with system level behavior, sort of KPIs or goals.

And we say, well, we want these high level rolled up statistics to move like this.

But in fact, you can't mutate the high level statistics.

They're just views or perspectives on a much more complex system.

So you need to basically adapt or impose certain policies, and those policies get implemented as rules or incentives or procedures of some kind.

And then, of course, that policy layer fills that sort of process model we had in the previous slide, and then agents behave.

And they behave in a way that is influenced by those policies.

They're influenced by their own perceptions of the system-level behavior and each other, and ultimately the actual system-level outcomes are emergent.

And what we're trying to do is sort of design things in this policy goal setting layer, the rules, incentives, et cetera, that can help steer the system towards system level goals without assuming necessarily that those system level goals are defined sort of externally.

So, you know, in most of my work, rather than saying, hey, I want people to do this,

I'm asking, hey, people want something to happen.

We don't know what it is.

But through a sort of more signal processing view of a decision-making protocol, we can actually design policies whose goal is to get that information and synthesize it, as opposed to simply force a particular outcome that maybe the policymaker has.

So in the context of computer systems, we can talk about the difference between a constitution and the technology.

So constitution is the definitions of the rules and processes and procedures

the in a sense the legal bits and the technology aspect is the implementation of it and what we find is that um there's an overlap here in this thing we call a computational constitution which is the subset of the um

of the procedures, rules, expectations, et cetera, that are actually enshrined in code.

And as a result of that, you can sort of see a sort of programmability and an enforcement of those rules in code

while also relying on sort of an outer human process to adapt those rules and make changes as needed.

And we tend to use access controls as an analogy here.

So you have the right to do a certain thing under certain conditions, and you can have a computational state that manages your roles, what rights those roles

confer you and how to exercise them.

Because this is a relatively short talk, I'm probably not going to go into too much detail.

You could give a 30 minute talk just on this slide, but it's an overview of what we see happening in the sort of technological plus human sort of almost sort of cybernetic communities.

Now, what's really interesting about these communities is that they're starting to proliferate in a way that's overlapping.

So you see groups of people and projects working together on certain tasks, and then the outputs of those tasks

It's being used as inputs to future tasks.

And you get a bunch of communities and projects interconnected in a sort of network of networks.

I really like the simplicial complex representation of this because a lot of the times things are tuples.

In particular though, there's an example here on the left, a project I've been working on is called Conviction Voting, and another one is called Community Inclusion Currencies.

And there's like an overlap between the organizations that are working on these things.

They have some shared research components, some shared execution components, but they also have a pretty different group of teams.

And so we can see that we have this,

complex structure and that more broadly we see a large number of these interconnected there's sort of many in the aragon ecosystem and in particular some data collected by this medigov project in particular this sub project is called govbase we're building a data set of lots of projects and the tools that they're using as well as their governance procedures and the

their licensing choices, et cetera.

And one view of that dataset is this bipartite graph between projects and tools.

And you can sort of see the projects that are using some of the same tools.

Now, some of those tools are like, you know, standard Web2 platforms, but some of them are actually the very things being built by the projects on the left.

that's being built by my team in a community that I've helped sponsor.

There's SourceCred in here and Aragon, which is a platform for DAOs.

So we start to see a non-trivial set of relationships between projects, tools, and actually communities that are running those projects using those tools.

Now I want to sort of zoom in on something a little bit more concrete for the purpose of this presentation.

So one of the design patterns for these types of organizations is this quote unquote cyber physical commons, which is a design that I worked on with the common stack and it involves a handful of components and it largely includes the ability to

raise funds and make decisions to allocate those funds and to sort of escrow and review work in order to issue those funds to people who have completed tasks as proposed.

This is a pretty standard set of questions.

It's not exhaustive, but it's a good place to start when you are looking at sort of community management and you want to do some collaborative production and maintenance of what you've produced.

So we realized that the governance part or the decision making of how to expend funds was a real blocker.

Many projects have tried sort of standard voting procedures and really just not gotten the engagement levels or even just like the sense that people feel like they're being heard.

And so we wanted to revisit the question of what voting is.

And so as a complex system scientist,

control theorist, I ask this question in very formal terms.

So we have signals on one side, we have signals on the other side, but it turns out the input signals are private, distributed, continuous, time varying.

It's just everybody's preferences.

And obviously that's a pretty high dimensional thing.

And the output has to be a public centralized event.

and to be honest like that's a huge dimensionality reduction so obviously there's no one unique solution to this problem and if anyone's familiar there's some like more canonical analysis of voting processes from arrow that says it's impossible for voting to meet

a set of fairness axioms.

And this goes even beyond that by just saying, this is a massive dimensionality reduction.

Therefore, there can't possibly be a sort of unique optimal solution to this problem.

It's gonna depend on context and what this community is trying to accomplish, their norms, preferences, et cetera.

So in practice, it's beyond even just choosing what the voting accounting procedure is, because when we have an algorithmic policy that determines an event from the input actions, we need to think about how one obtains and asserts their rights to participate.

And in these systems, we also often have magnitude.

So you might have a right to vote, but you also might have a quantity or sort of mass of voting power, depending on maybe your past contributions to the project or sort of other ways of modulating the difference between someone who sort of just showed up and joined and is new to the community versus sort of long standing contributor.

where you don't want to overweight it and exclude the new people, which at the same time, you need to find a way to strike a balance in the decision-making.

So we often do this by policies around not just obtaining the right to participate, but the magnitude of that right.

Additionally, it's really important to understand who has the right to add or remove the actual options.

So you look at a voting process and say, well, I have two choices and I hate both of them.

It doesn't really matter that you have the right to participate in that voting process if you're not being offered a choice that's meaningful to you.

In this sense, we say that, yeah, okay, the method of asserting and accounting of a vote is important, but so too is how one obtains that right and how

a potential choice in the first place.

And so we again revisit the fact that there can't exist an optimal voting process.

Instead, we have to really look at this from a contextual basis.

The algorithm that we are using in our work here is called conviction voting, and it's essentially a leaky integrator or a low-pass filter.

It just basically means that people are doing a kind of approval voting.

They're taking whatever number of tokens they have.

And that's their magnitude.

And they are expressing them in favor of any number of proposals.

So if I have 100 tokens, I might put 45 on proposal X, but I might put 55 on proposal Y or hold back the other 55 and look for another opportunity.

But what I'm essentially doing is an approval voting or a weighted approval voting over a sort of open-ended list of proposals.

A new proposal might arrive.

In any case, the way that this algorithm works for allocating funding is essentially to charge up this battery or this capacitor, and when it surpasses a certain activation energy, a proposal passes, a bit like a neuron firing.

So we have a sort of

inspired model for how we got to this algorithm in practice we build CAD CAD models so these are sort of hybrid sort of network agent based models we have participants and we have proposals we have private signals related to affinity and we sort of manage these data structures as Network X objects which are bipartite graphs and we can actually look at the way the system evolves over time and this is a quick experiment from

basically a video capture from one of these sort of agent-based dynamic network models.

And the left side in red is all the participants.

The size of the dot is how much magnitude they have.

If you notice, there are new agents arriving on the left.

There's more red dots appearing.

There are new proposals arriving on the right.

Those are the blue dots are candidates.

Yellow dots are past but not yet completed.

And green dots are completed projects.

you can sort of see that he's charging up and there's a variation in the size of the dots on the right as well because you actually have different size requests for funding and we use a different um required support for projects that request larger amounts of funds so

Here's a snapshot of one run in this experiment.

And you can see there's an accumulation of candidate funds, which is amount of funds being requested.

Active funds are projects that are currently running.

Completed funds are the funds associated with projects that have

been completed and killed means the project didn't maintain enough support and got dropped off the list and failed means a project was actually funded but then it was not successfully executed and there's a there's a sentiment model in the background that gives a feedback loop for the sort of future available funds so if you're not actually succeeding in passing proposals and completing them you're going to see a depletion in the available funds to allocate

The nice thing about this is it's not just simulations.

We have had a live test case running with onehive.org for the last few months, and you can check that out.

If you happen to have honey tokens or wanted to buy them, you can even participate in voting on these proposals.

The way that that organization works is that the organization itself owns some tokens that they can sell, but they also

have a procedure through which funds for projects are given in Honey.

So largely the Honey holders are people who have been contributing projects over time, and they use that token to assert their right to participate in voting for future proposals that get funded.

And actually this org is managing tens of thousands of dollars.

Actually at the moment it looks like it's over 100,000, but that's actually recent.

So apparently people are really enjoying this work.

A little bit of an overview to wrap up this point.

The solution, even the test case in Honey, is not exhaustive here.

We've left a lot of other components up for future adaptation.

We add a proposal for consideration, anyone can do it.

Risk is proposal spam, but we really haven't had that issue because it's community managed.

Could be in the future as it scales up.

You can vote on proposals, the tokens are transferable, they have magnitude.

There's always a risk of plutocracy here.

There are ways to limit this through implementation of strong identity like BrightID or to use a threshold that says if you have more than a certain amount,

tokens then you get a allocation of votes but that's the same for everyone who's above the threshold.

These are ways of addressing these concerns if they become a problem and you know furthermore we have issues with potentially people not doing the work they agreed to do but there are procurement and bidding systems like Giveth.

You can have escrows and independent review processes

is also supported by tools like Giveth.

And governance at the sort of, we'll call it like council level is also possible using another layer of access control and role-based tokens.

This is scaling up to a big, much larger test case run by Aragon.org, which is actually running currently.

When I first wrote this presentation, it hadn't yet launched, but it launched this week.

I would recommend checking out.

It's a much larger organization

The Aragon project has had a very, very large launch a couple of years ago.

The tokens that can be used for voting in this pilot are very widely distributed across a large number of people.

And it would be interesting to analyze the data that comes out of this six-week snapshot pilot on the Aragon network.

And so I will sort of close on this discussion of computer aided governance.

So a lot of my work relates to digital twins, which is basically building computational models that marry theory and data to give us visibility into the sort of trajectories of complex systems.

And what we observe is that when these types of models and they do exist,

are opaque and proprietary in governments and corporations they become effectively tools of authoritarian control but when they're open source and transparent and they're sort of part of a community project you can sort of see them as sense-making tools and they can provide support for data-driven discourse and collective decision-making where instead of just saying well if we do this i think that's going to happen

And someone else says, well, no, if we do that, this other thing is going to happen.

And you just argue about the consequences of the decision.

It can be very difficult to actually make progress.

But if you have some shared open source tools that help you say, hey, it looks like if we do this, this will probably happen, but that might happen.

How's the trade-off look?

What do we want?

And so I'm a big advocate for the sort of democracy in the information age being driven by open source algorithmic policymaking.

And it starts by understanding that all algorithms essentially have some

a subjective assumptions in the way that they're approached even the quote-unquote model-free um algorithms are still compressing information that's buried in data and the data itself has some some properties maybe some biases a wide range of of of things that it's important to address and understand what assumption you're making and bring that up to the forefront when you're going to be using those algorithms in some form or another to sort of

either govern decision-making processes or when the decision-making processes output algorithms or procedures.

So if you're interested in any of this stuff, I do work through the Vienna University of Economics and Business as an affiliated researcher.

I run a design firm called Block Science.

We have a token engineering discipline on the rise.

We have a Discord and a growing community applying these complex

systems concepts to designing tokenized systems and the common stack, which is the project from which this particular research was drawn.

And our tooling is called CADCAD.

It's a Python open source tool for generalized dynamical systems.

If you wanted to follow up on any of these things, here's some information about how to connect with these three organizations.

So apologies if I ran a little long.

Thank you very much for listening.


SPEAKER_00:
Thank you very much, Zargum.

That was awesome.

Great applied complexity, and you really brought it together with some of these representations.

So is there anything else that you wanted to add before we go to our next speaker, Jason?


SPEAKER_04:
I mean, I think I'm good.

I'll be around in KeyBase a little bit if people want to chat.

We're always looking for people to participate in sort of learning how to use the tools and we're growing a couple different open source communities.

Both the token engineering community is an open source growing engineering discipline.

The common stack is an open source project and CADCAD is an open source project.

So anybody who's excited about those things should definitely reach out to me and I'll try to connect them with the right communities.

Great.

See you later.

See you.


SPEAKER_00:
So our second speaker for this morning live stream is going to be Jason Larkin, who also has been a multi-time facilitator with Complexity Weekend.

And we're going to have this session go till 11 AM.

And then wherever we're at, whatever we're excited to talk about, we're going to continue at this gather.town link, which is in the program.

With that being said, Jason, please get us somewhere where we'll be ready to make sense collectively after it all finishes.


SPEAKER_05:
No, you can't start like that.

It would give me that pressure.

All right.

I already have a title, which is complete antithesis to what you just said, which is that this sense-making stuff is very hard, and I'm still trying to make sense of sense-making itself.

But this is kind of like a I'm going to show some slides and I think I'm going to try to keep this to like a high level narrative.

You know, the slides are available.

I can even make the PowerPoint available.

So like all the links and the actual stuff in it, you can go and look at yourself easily because I haven't finished my thoughts on this.

And this is just a set of slides which highlights some stuff, which I think is important.

OK, so let's see.

Next slide.

All right, so I've been doing this work with Daniel's help here, and also RJ, who I think is in the chat.

He's doing work for the Atlantic Council on sensemaking, and I'm helping him out with aspects of AI and its effect on sensemaking, or whether AI makes sense to us, whether it can help us make sense, so forth.

Although I'm going to show a little bit of stuff at the end about what the COVID impacts mental health team is doing, sort of on this same idea of sensemaking.

And I guess I also represent the PhD mentors.

And I think this actually, the stuff I talk about in here, I know throughout a lot of the mentoring I've done, these topics have come up over and over again, this sensemaking problem, which is very broad and generic, those words, I know.

So, okay.

So,

One of the standard things here is to include how COVID is affecting things.

So it seems something like COVID is really illuminating the sense-making problem where there's a bunch of topics on this page here.

And I think everyone here is aware of those topics and the controversies surrounding them and the positions people, like different parts of the population and different institutions even that take on these topics.

But it seems like everything's all scattered.

know it's really hard to make sense like what is true and and and these kind of things i know the words i'm using right now these are all like they're not they're pretty fluffy because then you can ask what does truth mean and those kind of things okay

So I think one of the major ways to frame this problem is to think about or look at sense-making versus matching, which is a lot of what we do as humans sort of innately.

We match versus trying to make sense.

So we look around at things that match what our current worldview is or what we might like it to be and those kind of things.

Yeah, so I think this is a nice definition of it, the sense-making crisis.

But instead of thinking of it as a sense-making crisis,

which I think is still a good way of thinking of it.

Explosion of data, you know, you can look at this just in raw trends from like how much data captured or is produced by Google, for example, it's just a ridiculous amount.

But I like this way of framing it too, because it's talking about, you know, like again, like the bias is sort of inherent to us

It's shared, it's an environment problem with the proliferation of information, but also we have a role to play.

And this role often seems to be this matching thing where we seek to find things that match our sense or current sense rather than actually trying to make sense.

And there's some nice links here.

I'm thinking like we can leave this afterwards or you can look at these individually, but a lot of this content here we'll discuss more about the things I just mentioned.

But in the effort to try and get through it all in the time allotted, I'll just go ahead and sort of skip over it some more.

Some other interesting data that I think a lot of you have already seen is like looking at these interesting and noted biases in media or in political parties.

And then other like focusing on social media, which is a really great place to mine and look for this, these kind of trends and biases.

I'll talk a little bit more about that later.

So then I'll sort of on the opposite side, let's just say political bias and stuff like that.

What about like existential bias?

You know, you can get that extreme where there's like a cohort of people who just think, oh, well, just everything's doing better and humans are getting better at everything, everything.

Lots of things about what it means to be a human is getting better, like violence and these kind of things.

And it's sort of everything's taking care of itself, so to speak, from an existential standpoint.

On the flip side, you have people who believe the doomsday is around the corner any minute.

And probably the sense is made somewhere in the middle there, but this is by no means some exhaustive list of interesting biases.

There's like almost too many of them.

These are just the ones that I thought sort of spanned a very wide spectrum of like political bias, which is still very important to like existential bias.

I think you have to sort of consider a lot of these things when you're trying to figure things out.

Okay, so then back to like the fundamental like myths or disinformation or just information proliferation problem.

is that, yeah, it really makes it very difficult to make sense of things.

I think another thing that plays a very important role, an active role, are all the dynamics from memetics.

I have some references here listed on this page, and there's also a bunch more in the extended.

But the important parts are like, well, how do these ideas spread?

Like, what makes an idea durable?

Then analysis of the idea, like,

how good or how much utility does the idea have itself, not just its propagation utility, but that there's a whole host of evolutionary ways or things that need to be taken into account when you think about, well, why is this information spreading?

Or why is this myth or disinformation spreading?

What makes it attractive to be spread in the first place?

What makes it attractive as an idea?

So that's an important part of it.

Then I also started thinking about coming up with so-called hard tests of sense-making.

Like, and it seems like it would lie along these controversial lines.

Like, so I don't really have much political affiliation, but an interesting test might be to ask, what has happened positively because of Trump administration policies?

So, like, you have the mainstream media and you have the noted bias and you have the way they've covered.

But what is the truth of it?

Like, actually, you know, has anything he actively did have any positive externality?

This is not to say that I'm not commenting on the rest of his administration, but just these kind of questions, I think, really probe at the heart of the matter.

Like, what are these hard questions where it's really hard to make sense of things?

On the right, it was an infographic I saw recently, and it actually has, I think what seems like reasonable data.

Oh, I haven't fact-checked the whole thing.

But the representations and so forth, the percentages of different things, it seems reasonable.

But then you have to lift up to a higher level beyond just like, oh, is this, you know, accurate representation of some statistical data?

It was like, what does it mean?

Like, there are some interesting, you know, dimensions or labels or whatever you want to call them being

represented in this graphic, but what is the person trying to say who made it or did they have an agenda?

But I think it further goes to show how difficult this sense-making is because it's kind of like the confluence of all these complex systems and you have to use some important or some strong heuristics to figure out what is going on.

I also like this drawing here because it's someone's

a creative attempt or interesting attempt to try and zoom out to some high level and try to sort of paint the world in terms of all the problems and interconnectedness it might have.

Of course, this one doesn't do that, right?

But I think it is an interesting attempt and it's in some sense captures what we're talking about here, which is oftentimes it's very difficult to make sense of the conflict system because you're just simply blind to huge portions of it or you haven't found the right representation that elucidates what are the important aspects.

That was interesting.

And I brought this up last time too, in the context of like your own mental health and like your, your information diet.

Um, so this comes up back again, this, this, uh, there's a kind of a dichotomy here.

I listed, uh, there's a data report.com.

This is a Taiwan has very like transparency on their public policy data.

So it's like highly accessible.

Like you can do a lot with it.

Um, at the same time though, you know, we have this, we have an issue here at scale, like in the U S we're heterogeneous and there's, there's,

at least a curtain of more emphasis on individual identity and that sort of thing.

Um, and, but what's interesting to ask is like when you have this exponential tech, like mainstream media and so forth, like what are the rules and regulations, like how, how open and free speech can you really have?

And I'm not saying that, I don't know the answer to that question, but it certainly brings that up.

And, um, so I think this is like along the lines of people like Tristan Harris, uh, another one here is Renee.

So they've both spoken out about this, about how precious your attention is, how pernicious some ideas can be from a mimetic standpoint, bad ideas.

And what are we doing to figure out how to mitigate this stuff?

Or can we even identify that stuff regularly?

Does anyone in the world have an algorithm or a set of rules to figure out, well, that's hate speech, and that's something we shouldn't pay attention to, and so forth?

But these are all very difficult questions, I think.

What can be extracted, I think, is like a first principle, is that attention is finite.

And actually it seems to be dominated by what is often referred to as systems one thinking versus systems two, where systems one is involved with a lot of automated response and it's kind of a poor approximation to behavior or to decision-making.

Whereas systems two seeks to, it's like the,

the part of your mind which is working when you can only digest some reading or mathematics or something for only a few hours a day.

You have a limited supply of it.

So all your attention, maybe only like one tenth of it actually is useful at synthesizing and combining these complex ideas.

So yeah, at the end of the day, I mean, attention is pretty precious.

It's a precious resource.

So I think, you know, Tristan, I don't think is right about everything, but this seems to be something that he's right about.

Okay, then the other thing with sort of making sense is the matching problem, and that has a lot to do with core beliefs problem, or maybe an inability to modify one's core beliefs.

So I think that a huge part that plays here in the core beliefs problem is basically the core beliefs themselves.

What are your core beliefs or first principles?

Then how do they match up with the external reality, with the real world?

Another interesting thing to consider is, like I mentioned, what are your core beliefs?

What are these so-called first principles?

And what I seem to see a lot happening within dialogue on mainstream media and there's institutions and all these conversations happening is it seems to be like a lot of times these conversations have degenerated into a lower tier on what Ken Wilber in his integral theory characterizes as the top level is this like sort of fully integrated level.

And all the ones below it follow like from egocentrism at the bottom through authoritarianism, ethnocentrism to modern and postmodern and so forth.

And I just see this happen like this seems to be a major feature of a lot of different

communications, I'm talking about across, you know, established media, so New York Times and stuff like that, although they're online a lot now, to mainstream media, to social media and institutions communicating with each other, people within institutions communicating, inter-institution, all that stuff.

I see this often in terms of how conversations degenerate and communication breaks down.

Some other solutions I found personally useful are, it helps a lot to, and you sort of do this as you read somebody, some critic or some scientist, whatever it is, as you get to know them through their prose and what they're writing.

And it's a lot like Nietzsche says, like they can try and sort of hide agendas, but those often just shine right through if you have enough sample of the person's writings.

And I think it also helps to sort of know the person, like, you know, what are their biases?

Like, this helps a lot within this community.

We can talk with each other.

We share openly.

And there's all kinds of information contained in those exchanges, which helped all of us to make sense.

You know, was what this person is saying true?

Does it fit in with what they're used to saying?

And all these kinds of things.

And then I also like this list of things that traits of the disinformation list, things that people tend to do when they're trying to disinform.

or white lie, or obfuscate the truth, or skate over things, and that sort of thing.

Oh, and I also think it's helpful for a lot of people to try and modify the objective of reading.

Like, not try to utilize what you're reading to come to some sharp conclusion, but simply, let's say, like, in Sam Kainer's model of spectrums of agreement, you're simply trying to figure out, you know, is this article, I strongly disagree with this.

Maybe you should do a post and, what is it, post hoc, after hoc.

Did I agree with it before?

How much do I agree with it after?

Do I only seek stuff that I'm going to strongly agree with?

Probably shouldn't do that.

We've seen how that gets deranged.

So I think this is usually what I sort of try to follow when I go into a situation.

But then I think there's also like these social theory problems with this gradients of agreement that is it's hard to come to coherence in voting schemes when you allow people to sort of

So it's interesting, I think, that you have to transition to some sort of smaller scale or lower dimensional representation than this when you actually want to get things done.

That might be something inherent to systems, but I'm not sure.

Maybe Zargum probably had something to say about that.

I'm sorry.

I was in the green room for your talk.

We can talk after.

Oh, another heuristic I use is I tend to seek out disagreeable people.

When they're disagreeable, but you don't have any expertise, you're a troglodyte.

But when you have expertise and you're disagreeable, you just have a good assessment of the risk of the system in my experience.

So I just kind of like always seek these kind of people out because they seem to, on average, be able to tell me like the honest assessment of what the situation is, not some kind of overinflated hype thing.

I like these words from, from Eric Weinstein.

He's an interesting guy at Teal Capital.

Um, and then he made a list of his own little ad hoc list.

Here's some other people I think fit this mold in terms of traits and so forth.

And that's actually a very nice list.

I follow those, all those same people on Twitter myself.

I have something to say about Twitter later, but, um, uh, I think it's nice, like following a set of individuals, finding those individuals within institutions for me is, it's very effective at trying to make more sense of things.

Um,

I'll have more to say on the Twitter thing later.

Okay, yeah, so some solutions we can come up with here is something like we need to increase the first principles awareness of all readers.

And what first principles?

Well, probably every first principle, every topic that is relevant to whatever phenomena we're observing, which means like if we're observing economy, we probably need to know about human psychology and

a whole bunch of other stuff.

I mean, this is all in line with the complexity weekend idea.

But the best way you can stop from fooling yourself about correlation, poor correlation causation is to understand the system from a first principles standpoint.

You can still go awry there, but at least it helps.

But then the counter example to this, or the...

the argument going against this first principles thinking would be something like, well, now the world is way too complicated, much more complicated than in 1900.

So like the David Hilbert quote about like, well, he can know all mathematics more or less back then.

Little did he know, right?

But now, even today, he'd probably struggle.

I mean, the world's very complicated ways.

Okay, so those, I think those are some solutions.

But I think also what you arrive here is that like this reading device, app, whatever it is, the thing that helps you make sense,

It needs to be well understood by the person using it.

I don't think there is a way to make some app that just condenses all of reality and so forth into a digestible form for everybody.

I think you need to have a participation with this technology to actually get it and actually to trust it for it to make sense to you.

I think that's sort of like inherent.

Okay.

Yeah.

So what another, an interesting manifestation of all this is I've switched over to her, like with this barbell thinking that has been said, uh, and I seem to love, I think he quoted it cause it has a conceptual thing in finance, but it's basically like I've switched to just looking at Twitter, the archives, um, like all these ways of quickly getting stuff to market, so to speak ideas.

And then like reading like books and journal articles and stuff that are durable, but he's, they're really right.

Like if you look at a lot of,

you know, articles in New York times and these different magazine outlets and so forth over like their years, a couple of years old and stuff.

They just haven't survived.

They're not very durable.

Um, so at least in my own, in my own work, I really have made this at least inclusion of Twitter.

Cause if you follow the right people, they're actually talking about relevant things.

Like I know Twitter has reputation for just being a shit show or something, but, and I've seen it, but if you follow the right people, like they're actually trying to get work done and express ideas and, um,

Oh, okay.

This is interesting.

So now we're going to start playing on Reddit and on with the COVID mental health team and trying to see what we can leverage from, because Reddit's an interesting media platform.

It has the upvoting system.

So it has an element of community enforced quality a la Wikipedia.

It's not as good as Wikipedia, but it has that trend at least.

And then trying to go sort of back and go across different corporate Reddits and see if we can

The other thing is that all the data is like highly human labeled.

So you can then use that with machine learning techniques and ask, is there a faithful representation in the labeling they gave it?

Does it differ significantly in the current climate of the company or other entities?

But yeah, there's a lot that can be mined and derived from.

But then one has to go in with figuring out what are the inherent biases and what's the incentive for employees to go on Reddit and, you know,

give a preference, they don't have to enforce preference falsification and these kinds of things.

So that's another thing we're gonna be doing with the other teams.

So if like anyone on the call or whatever is interested, we're gonna be making like the notebooks and stuff we work in available if you wanna try to do your own analysis.

Okay, so now we're in bonus slide time.

Like those are all the slides that I, you know, organize or try to, still not very organized.

So now we're onto just whatever questions or


SPEAKER_00:
I think it's a perfect timing, Jason.

Thank you very much.

Awesome.

Well, in this last one minute, let's think about how we can move to a sense-making context in a spatial chat through this gatherer.town link.

I think I will just close out the live stream for those who are just listening.

For those who are live, if you go to the link that's in the program, you'll see a login link that looks like this.

And here you can enter your name and you should see yourself as a little video chat person.

Put your name as your first name and then your key base name if you'd like, and then join the gathering.

And so this is a space where people can do spatial chat.

You can walk around in a room.

And you will find other people who are near you.

So yeah, we will meet you over here for 20 minutes.

And then at 1120 AM, we're going to pick back up at the shared Jitsi link that's also in this calendar at the window that I'm looking at right now.

Any final thoughts there, Steve?

Oh, you're muted.

One second.


SPEAKER_01:
A lot of great stuff in there, Jason.

Thanks so much.

We'll see everybody and gather.


SPEAKER_00:
Awesome.

We will see you there.

Thanks so much for listening.

Please, if you're watching it in replay, feel free to join our complexweekend.public team.

I'm going to